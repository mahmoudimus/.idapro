# generated by mutilz cli at 2025-03-18 14:20:21
import collections
import dataclasses
import functools
import itertools
import logging
import re
import struct
import time
import typing
from dataclasses import dataclass, field
from enum import Enum, auto

import capstone
import ida_allins
import ida_bytes
import ida_funcs
import ida_ida
import ida_idaapi
import ida_idp
import ida_kernwin
import ida_segment
import ida_ua
import idaapi
import idautils
import idc
import mutilz.actions as actions
import mutilz.helpers.ida as ida_helpers
from mutilz.helpers.ida import clear_output, format_addr
from mutilz.logconf import configure_debug_logging

logger = logging.getLogger("mutilz.actions.remove_anti_disassembly")
configure_debug_logging(logger)


# fmt: off
# NOP patterns from the source code
NOP_PATTERNS = [
    # 1-byte NOP
    [0x90],
    # 2-byte XCHG AX,AX
    [0x66, 0x90],
    # 3-byte NOP DWORD ptr [RAX]
    [0x0F, 0x1F, 0x00],
    # 4-byte NOP DWORD ptr [RAX + 0]
    [0x0F, 0x1F, 0x40, 0x00],
    # 5-byte NOP DWORD ptr [RAX + RAX + 0]
    [0x0F, 0x1F, 0x44, 0x00, 0x00],
    # 6-byte NOP WORD ptr [RAX + RAX + 0]
    [0x66, 0x0F, 0x1F, 0x44, 0x00, 0x00],
    # 7-byte NOP DWORD ptr [RAX + 0] (variant)
    [0x0F, 0x1F, 0x84, 0x00, 0x00, 0x00, 0x00],
    # 8-byte NOP DWORD ptr [RAX + RAX + 0] (variant)
    [0x0F, 0x1F, 0x84, 0x00, 0x00, 0x00, 0x00, 0x00],
    # 9-byte NOP WORD ptr [RAX + RAX + 0] (variant)
    [0x66, 0x0F, 0x1F, 0x84, 0x00, 0x00, 0x00, 0x00, 0x00],
    # 10-byte NOP with extra prefix
    [0x66, 0x66, 0x0F, 0x1F, 0x84, 0x00, 0x00, 0x00, 0x00, 0x00],
    # 11-byte NOP with three 0x66 prefixes
    [0x66, 0x66, 0x66, 0x0F, 0x1F, 0x84, 0x00, 0x00, 0x00, 0x00, 0x00],
]

CONDITIONAL_JUMPS = list(range(ida_allins.NN_ja, ida_allins.NN_jz + 1))
ALL_JUMPS = CONDITIONAL_JUMPS + [ida_allins.NN_jmp]
CALL_INSTRUCTIONS = {ida_allins.NN_call, ida_allins.NN_callfi, ida_allins.NN_callni}
CONDITIONAL_JUMPS_MNEMONICS = [
    "ja",
    "jae",
    "jb",
    "jbe",
    "jc",
    "jcxz",
    "jecxz",
    "jrcxz",
    "je",
    "jg",
    "jge",
    "jl",
    "jle",
    "jna",
    "jnae",
    "jnb",
    "jnbe",
    "jnc",
    "jne",
    "jng",
    "jnge",
    "jnl",
    "jnle",
    "jno",
    "jnp",
    "jns",
    "jnz",
    "jo",
    "jp",
    "jpe",
    "jpo",
    "js",
    "jz",
]


# Define padding pattern (common in anti-disassembly sequences)
PADDING = rb"((\xC0[\xE0-\xFF]\x00)|(\x86|\x8A)[\xC0\xC9\xD2\xDB\xE4\xED\xF6\xFF])"
# --- Reusable Padding Pattern ---
# First, define the raw padding pattern without capturing groups.
PADDING_PATTERN = rb"(?:\xC0[\xE0-\xFF]\x00|(?:\x86|\x8A)[\xC0\xC9\xD2\xDB\xE4\xED\xF6\xFF])"
# (We do not wrap this in a named group here so that we can reuse it inside other groups.)

# --- Enum for Pattern Categories ---
class PatternCategory(Enum):
    MULTI_PART = auto()
    SINGLE_PART = auto()
    JUNK = auto()

# --- Dataclass for Regex Pattern Metadata ---
@dataclass
class RegexPatternMetadata:
    category: PatternCategory
    pattern: bytes  # The regex pattern as a bytes literal
    description: typing.Optional[str] = None
    compiled: typing.Optional[typing.Pattern] = None

    def compile(self, flags=0):
        """Compile the regex if not already done, and return the compiled object."""
        if self.compiled is None:
            self.compiled = re.compile(self.pattern, flags)
        return self.compiled

    @property
    def group_names(self):
        """Return the dictionary mapping group names to their indices."""
        return self.compile().groupindex

@dataclass
class MultiPartPatternMetadata(RegexPatternMetadata):
    category: PatternCategory = field(default=PatternCategory.MULTI_PART, init=False)

    def __post_init__(self):
        # Compile to ensure group names are available.
        _ = self.compile(re.DOTALL)
        required_groups = {"first_jump", "padding", "second_jump"}
        missing = required_groups - set(self.group_names)
        if missing:
            raise ValueError(
                f"MultiPart pattern is missing required groups: {missing}"
            )

@dataclass
class SinglePartPatternMetadata(RegexPatternMetadata):
    category: PatternCategory = field(default=PatternCategory.SINGLE_PART, init=False)

    def __post_init__(self):
        _ = self.compile(re.DOTALL)
        required_groups = {"prefix", "padding", "jump"}
        missing = required_groups - set(self.group_names)
        if missing:
            raise ValueError(
                f"SinglePart pattern is missing required groups: {missing}"
            )

@dataclass
class JunkPatternMetadata(RegexPatternMetadata):
    category: PatternCategory = field(default=PatternCategory.JUNK, init=False)

    def __post_init__(self):
        _ = self.compile(re.DOTALL)
        required_groups = {"junk"}
        missing = required_groups - set(self.group_names)
        if missing:
            raise ValueError("Junk pattern must have a 'junk' group.")
    
# Multi-part jump patterns: pairs of conditional jumps with optional padding
MULTI_PART_PATTERNS = [
    MultiPartPatternMetadata(rb"(?P<first_jump>\x70.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x71.)", "JO ... JNO"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x71.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x70.)", "JNO ... JO"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x72.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x73.)", "JB ... JAE"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x73.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x72.)", "JAE ... JB"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x74.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x75.)", "JE ... JNE"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x75.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x74.)", "JNE ... JE"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x76.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x77.)", "JBE ... JA"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x77.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x76.)", "JA ... JBE"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x78.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x79.)", "JS ... JNS"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x79.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x78.)", "JNS ... JS"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7A.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7B.)", "JP ... JNP"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7B.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7A.)", "JNP ... JP"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7C.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7D.)", "JL ... JGE"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7D.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7C.)", "JGE ... JL"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7E.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7F.)", "JLE ... JG"),
    MultiPartPatternMetadata(rb"(?P<first_jump>\x7F.)(?P<padding>" + PADDING_PATTERN + rb")*(?P<second_jump>\x7E.)", "JG ... JLE"),
]

# Single-part jump patterns: prefix instruction + optional padding + conditional jump
SINGLE_PART_PATTERNS = [
    SinglePartPatternMetadata(rb"(?P<prefix>\xF8)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "CLC ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF9)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x76.)", "STC ... JBE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF9)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x72.)", "STC ... JB"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xA8.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST AL, imm8 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xA9....)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST EAX, imm32 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF6..)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST r/m8, imm8 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF7.....)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST r/m32, imm32 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x84.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST r/m8, r8 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x85.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "TEST r/m32, r32 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xA8.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST AL, imm8 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xA9....)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST EAX, imm32 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF6..)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST r/m8, imm8 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\xF7.....)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST r/m32, imm32 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x84.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST r/m8, r8 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x85.)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "TEST r/m32, r32 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xE0-\xE7]\xFF)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "AND r/m8, 0xFF ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x24\xFF)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "AND AL, 0xFF ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xC8-\xCF]\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "OR r/m8, 0x00 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x0C\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "OR AL, 0x00 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xF0-\xF7]\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "XOR r/m8, 0x00 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x34\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x71.)", "XOR AL, 0x00 ... JNO"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xE0-\xE7]\xFF)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "AND r/m8, 0xFF ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x24\xFF)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "AND AL, 0xFF ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xC8-\xCF]\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "OR r/m8, 0x00 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x0C\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "OR AL, 0x00 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x80[\xF0-\xF7]\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "XOR r/m8, 0x00 ... JAE"),
    SinglePartPatternMetadata(rb"(?P<prefix>\x34\x00)(?P<padding>" + PADDING_PATTERN + rb")?(?P<jump>\x73.)", "XOR AL, 0x00 ... JAE"),
]


JUNK_PATTERNS = [
    JunkPatternMetadata(rb"(?P<junk>\x0F\x31)", "RDTSC"),
    JunkPatternMetadata(rb"(?P<junk>\x0F[\x80-\x8F]..[\x00\x01]\x00)", "TwoByte Conditional Jump"),
    JunkPatternMetadata(rb"(?P<junk>\xE8..[\x00\x01]\x00)", "Invalid CALL"),
    JunkPatternMetadata(rb"(?P<junk>\x81[\xC0-\xC3\xC5-\xC7]....)", "ADD reg32, imm32"),
    JunkPatternMetadata(rb"(?P<junk>\x80[\xC0-\xC3\xC5-\xC7].)", "ADD reg8, imm8"),
    JunkPatternMetadata(rb"(?P<junk>\x83[\xC0-\xC3\xC5-\xC7].)", "ADD reg32, imm8"),
    JunkPatternMetadata(rb"(?P<junk>\xC6[\xC0-\xC3\xC5-\xC7].)", "MOV reg8, imm8"),
    JunkPatternMetadata(rb"(?P<junk>\xC7[\xC0-\xC3\xC5-\xC7]....)", "MOV reg32, imm32"),
    JunkPatternMetadata(rb"(?P<junk>\xF6[\xD8-\xDB\xDD-\xDF])", "NEG reg8"),
    JunkPatternMetadata(rb"(?P<junk>\x80[\xE8-\xEB\xED-\xEF].)", "AND reg8, imm8"),
    JunkPatternMetadata(rb"(?P<junk>\x81[\xE8-\xEB\xED-\xEF]....)", "AND reg32, imm32"),
    JunkPatternMetadata(rb"(?P<junk>\x68....)", "PUSH imm32"),
    JunkPatternMetadata(rb"(?P<junk>\x6A.)", "PUSH imm8"),
    JunkPatternMetadata(rb"(?P<junk>[\x70-\x7F].)", "Random 112-127"),
    JunkPatternMetadata(rb"(?P<junk>[\x50-\x5F])", "Single-byte PUSH/POP"),
]   


# Define "big instruction" opcode arrays
SINGLE_BYTE_OPCODES = b"\xc8\x05\x0d\x15\x1d\x25\x2d\x35\x3d\x68\xa0\xa1\xa2\xa3\xa9\xb8\xb9\xba\xbb\xbc\xbd\xbe\xbf\xe8\xe9\x69\x81\xc7\xf7"
MED_OPCODES = b"\xa0\xa1\xa2\xa3\x00\x01\x02\x03\x08\x09\x0a\x0b\x0f\x10\x11\x12\x13\x18\x19\x1a\x1b\x20\x21\x22\x23\x28\x29\x2a\x2b\x30\x31\x32\x33\x38\x39\x3a\x3b\x84\x85\x86\x87\x88\x89\x8a\x8b\x8c\x8d\x8e\x8f\x6b\x80\x83\xf6"
BIG_OPCODES = b"\x69\x81\x6b\x80\x83\xc0\xc1\xf6"
ANTI_DISASM_EXTRA_BYTE = 0xF4
SINGLE_BYTE_OPCODE_SET = set(SINGLE_BYTE_OPCODES)
MED_OPCODE_SET = set(MED_OPCODES)
BIG_OPCODE_SET = set(BIG_OPCODES)
# fmt: on


class MemHelper:
    def __init__(self, start: int, end: int):
        self.mem_results = b""
        self.mem_offsets = []
        self.start = start
        self.end = end
        if not self.mem_results:
            self._get_memory(start, end)

    def _get_memory(self, start: int, end: int):
        result = idc.get_bytes(start, end - start)
        self.mem_results = result
        self.mem_offsets.append((start, end - start))


@dataclass(repr=False)
class PatchOperation:
    """Class to store patch operations that will be applied later."""

    address: int
    byte_values: bytes

    def apply(self):
        """Apply the patch operation."""
        ida_bytes.patch_bytes(self.address, self.byte_values)
        logger.debug(
            f"Applied patch at 0x{self.address:x} with value {self.byte_values.hex()}"
        )

    def __str__(self):
        """String representation with hex formatting."""
        return f"{self.__class__.__name__}(address=0x{self.address:X} , byte_values={self.byte_values.hex()})"

    __repr__ = __str__


@dataclass(repr=False)
class UnconditionalJumpOperation(PatchOperation):
    """Class to store unconditional jump patch operations."""

    byte_values: bytes = b"\xeb"

    def apply(self):
        """Apply the patch operation."""
        ida_bytes.patch_bytes(self.address, self.byte_values)

    def __str__(self):
        return super().__str__()


def is_x64():
    # Check if the current architecture is x64
    return ida_ida.inf_is_64bit()


def format_bytes(bytes_list):
    """
    Format a list of bytes as a string of hex values.

    Args:
        bytes_list (bytes or list): The bytes to format.

    Returns:
        str: A string of comma-separated hex values.
    """
    return ", ".join(["0x{:02X}".format(b) for b in bytes_list])


def parse_hex_string(hex_string):
    """
    Parse a string of hex values into a bytes object.

    Args:
        hex_string (str): A string of comma-separated hex values.

    Returns:
        bytes: A bytes object containing the parsed hex values.
    """
    # Remove whitespace and split by commas
    hex_values = hex_string.replace(" ", "").split(",")

    # Convert each hex value to an integer
    bytes_list = []
    for val in hex_values:
        # Remove '0x' prefix if present
        val = val.strip().lower()
        if val.startswith("0x"):
            val = val[2:]

        # Convert to integer
        bytes_list.append(int(val, 16))

    return bytes(bytes_list)


def get_jump_target(insn):
    """Calculate the target address of a jump instruction."""
    if insn.itype in [ida_allins.NN_jmp, ida_allins.NN_jmpfi, ida_allins.NN_jmpni]:
        op = insn.Op1
    else:
        op = insn.Op1 if insn.Op1.type == idc.o_near else None

    if op and op.type == idc.o_near:
        return op.addr
    elif op and op.type == idc.o_displ:
        return op.addr + insn.ea + insn.size
    return None


def fix_jump(jump_ea, target_ea):
    """Fix the jump at jump_ea to point to target_ea."""
    insn = idautils.DecodeInstruction(jump_ea)
    if not insn:
        return False

    current_target = get_jump_target(insn)
    if not current_target:
        return False

    disp = target_ea - (jump_ea + insn.size)

    # Handle short jumps (1-byte displacement)
    if insn.size == 2:
        if -128 <= disp <= 127:
            idc.patch_byte(jump_ea + 1, disp & 0xFF)
            return True
        else:
            # Convert to near jump (0xE9)
            idc.patch_byte(jump_ea, 0xE9)
            idc.patch_dword(jump_ea + 1, disp - 3)  # Adjust for 5-byte instruction
            idc.patch_byte(jump_ea + 5, 0x90)  # NOP the old byte
            return True
    # Handle near jumps (4-byte displacement)
    elif insn.size == 5:
        idc.patch_dword(jump_ea + 1, disp - 5)
        return True
    # Handle conditional near jumps (6 bytes: 0F 80-8F)
    elif insn.size == 6:
        idc.patch_dword(jump_ea + 2, disp - 6)
        return True
    return False


class SegmentType(Enum):
    STAGE1_SINGLE = auto()
    STAGE1_MULTIPLE = auto()
    JUNK = auto()
    BIG_INSTRUCTION = auto()


@dataclass
class MatchSegment:
    start: int
    length: int
    description: str
    matched_bytes: bytes
    segment_type: SegmentType
    matched_groups: typing.Dict[str, bytes] | None = None


class MatchChain:
    def __init__(self, base_address: int, segments: typing.List[MatchSegment] = None):
        self.base_address = base_address
        self.segments = segments or []

    def add_segment(self, segment: MatchSegment):
        self.segments.append(segment)

    def overall_start(self) -> int:
        return self.segments[0].start + self.base_address if self.segments else 0

    def overall_length(self) -> int:
        if not self.segments:
            return 0
        first = self.segments[0]
        last = self.segments[-1]
        return (last.start + last.length) - first.start

    def overall_matched_bytes(self) -> bytes:
        return b"".join(seg.matched_bytes for seg in self.segments)

    def append_junk(
        self, junk_start: int, junk_len: int, junk_desc: str, junk_bytes: bytes
    ):
        seg = MatchSegment(
            start=junk_start,
            length=junk_len,
            description=junk_desc,
            matched_bytes=junk_bytes,
            segment_type=SegmentType.JUNK,
        )
        self.add_segment(seg)

    @property
    def description(self) -> str:
        desc = []
        for idx, seg in enumerate(self.segments):
            if idx == 0:
                desc.append(f"{seg.description}")
            else:
                desc.append(f" -> {seg.description}")
        return "".join(desc)

    def update_description(self, new_desc: str):
        if self.segments:
            self.segments[0].description = new_desc

    # New properties for junk analysis
    @property
    def stage1_type(self) -> SegmentType:
        return self.segments[0].segment_type

    @property
    def junk_segments(self) -> list:
        """
        Returns a list of segments considered as junk based on their segment_type.
        """
        return [seg for seg in self.segments if seg.segment_type == SegmentType.JUNK]

    @property
    def junk_starts_at(self) -> typing.Optional[int]:
        """
        Returns the starting address of the junk portion.
        This is computed as base_address + the offset of the first junk segment.
        If no junk segments exist, returns None.
        """
        js = self.junk_segments
        if js:
            return self.base_address + js[0].start
        return None

    @property
    def junk_length(self) -> int:
        """
        Returns the total length of the junk portion.
        This is computed as the difference between the end (start + length) of the last junk segment
        and the start of the first junk segment.
        If there are no junk segments, returns 0.
        """
        js = self.junk_segments
        if not js:
            return 0
        first = js[0]
        last = js[-1]
        return (last.start + last.length) - first.start

    def __lt__(self, other):
        return self.overall_start() < other.overall_start()

    def __repr__(self):
        r = [
            f"{self.description.rjust(32, ' ')} @ 0x{self.overall_start():X} - "
            f"{self.overall_matched_bytes().hex()[:16]}"
            f"{'...' if self.overall_length() > 16 else ''}",
            "  |",
        ]
        for seg in self.segments:
            _grps = f"{' - ' + str(seg.matched_groups) if seg.matched_groups else ''}"
            r.append(
                f"  |_ {seg.description} @ 0x{self.base_address + seg.start:X} - {seg.matched_bytes.hex()}{_grps}"
            )
        return "\n".join(r)


class MatchChains:
    def __init__(self):
        self.chains = []

    def add_chain(self, chain: MatchChain):
        self.chains.append(chain)

    def __repr__(self):
        _the_repr = []
        for chain in self.chains:
            _the_repr.append(
                f"{chain.description.rjust(32, ' ')} @ 0x{chain.overall_start():X} - "
                f"{chain.overall_matched_bytes().hex()[:16]}"
                f"{'...' if chain.overall_length() > 16 else ''}"
            )
        return "\n".join(_the_repr)

    def __iter__(self):
        yield from self.chains

    def sort(self):
        self.chains.sort(key=lambda x: x.overall_start())


@dataclass
class JumpTargetAnalyzer:
    # Input parameters for processing jumps.
    match_bytes: bytes  # The bytes in which we're matching jump instructions.
    match_start: int  # The address where match_bytes starts.
    block_end: int  # End address of the allowed region.
    start_ea: int  # Base address of the memory block (used for bounds checking).

    # Define jump patterns to search within match_bytes.
    jump_patterns: list = field(
        init=False,
        default_factory=lambda: [
            rb"\x90*[\xEB\xE9].",  # JMP rel8
            rb"\x90*[\x70-\x7F].",  # Jcc rel8
        ],
    )
    # Internal structures.
    jump_targets: collections.Counter = field(
        init=False, default_factory=collections.Counter
    )
    jump_details: list = field(
        init=False, default_factory=list
    )  # List of (jump_ea, final_target, stage1_type)
    insertion_order: dict = field(
        init=False, default_factory=dict
    )  # final_target -> order index
    target_type: dict = field(
        init=False, default_factory=dict
    )  # final_target -> stage1_type

    def follow_jump_chain(self, mem, current_ea, match_end, visited=None):
        """
        Follow a chain of jumps starting from current_ea.
        Avoid loops or out-of-bounds jumps.
        """
        if visited is None:
            visited = set()
        # Avoid loops or jumps outside the memory block.
        if (
            current_ea in visited
            or current_ea < self.start_ea
            or current_ea >= self.start_ea + len(mem.mem_results)
        ):
            return None
        visited.add(current_ea)
        current_offset = current_ea - self.start_ea

        try:
            current_bytes = mem.mem_results[
                current_offset : self.block_end - self.start_ea
            ]
            # print(f"current_ea: {current_ea:X} , current_bytes: {current_bytes.hex()[:16]}...")
            # print(f"current_offset: {current_offset} , range: {current_offset}:{self.block_end - self.start_ea}")
        except IndexError:
            print(f"IndexError at {current_ea} with offset {current_offset}")
            return None
        # Try matching each jump pattern.
        # we do not modify current_ea because we need to be *EXACT*
        # via addresses to check if the target is within the valid
        # conditional range and whether the big instruction
        # falls at the last 6 bytes of the buffer
        curr_addr = current_ea
        while True:
            insn = ida_ua.insn_t()
            length = ida_ua.decode_insn(insn, curr_addr)
            if insn.itype == ida_allins.NN_nop:
                curr_addr += length
                continue
            # we only care about 2 byte jumps
            if insn.itype not in ALL_JUMPS or length != 2:
                break

            target = insn.Op1.addr
            print(
                f"  -> Found {idc.generate_disasm_line(curr_addr, idc.GENDSM_FORCE_CODE)} @ 0x{current_ea:X} targeting 0x{target:X}"
            )
            # If the jump target is within the valid conditional range,
            # # continue following the chain.

            if self.match_start <= target < match_end + 6:
                print(f"  -> -> Follwing 0x{target:X}")
                return self.follow_jump_chain(mem, target, match_end, visited)
            elif target == match_end + 6:
                return target
            # Otherwise, if the target is within the overall memory block, return it.
            return target if self.start_ea <= target < match_end + 6 else current_ea

        # for pattern in self.jump_patterns:
        #     match = re.match(pattern, current_bytes, re.DOTALL)
        #     if match:
        #         insn = ida_ua.insn_t()
        #         length = ida_ua.decode_insn(insn, current_ea)
        #         target = insn.Op1.addr
        #         print(f"Found {match.group().hex()} @ 0x{current_ea:X} targeting 0x{target:X}")
        #         # If the jump target is within the valid conditional range,
        #         # continue following the chain.
        #         if self.match_start <= target < self.block_end:
        #             return self.follow_jump_chain(mem, target, visited)
        #         # Otherwise, if the target is within the overall memory block, return it.
        #         return (
        #             target
        #             if self.start_ea <= target < self.start_ea + len(mem.mem_results)
        #             else None
        #         )
        # If no jump pattern matches, end of the chain; return the current address.
        return current_ea

    def process(self, mem, chain):
        """
        Process each jump match in match_bytes.
        'chain' is expected to have attributes:
          - junk_length: int
          - stage1_type: SegmentType
        """
        match_end = chain.overall_start() + chain.overall_length()
        for jump_match in re.finditer(
            rb"[\xEB\x70-\x7F].", self.match_bytes, re.DOTALL
        ):
            jump_offset = jump_match.start()
            jump_ea = self.match_start + jump_offset
            # offset = struct.unpack("<b", jump_match.group()[-1:])[0]
            # Compute the final target assuming a 2-byte instruction.
            # final_target = jump_ea + 2 + offset
            final_target = self.follow_jump_chain(mem, jump_ea, match_end)
            if not final_target or final_target >= self.block_end:
                continue

            if not (match_end < final_target <= match_end + 6):
                print(
                    f"  {jump_match.group().hex()} @ 0x{jump_ea:X} targeting 0x{final_target:X} is NOT within 6 bytes of match end {match_end:X}"
                )
                continue

            assert self.match_start + chain.junk_length <= final_target < self.block_end
            self.jump_targets[final_target] += 1
            # Record the insertion order and the stage1_type on the first occurrence.
            if final_target not in self.insertion_order:
                self.insertion_order[final_target] = len(self.insertion_order)
                self.target_type[final_target] = chain.stage1_type
            self.jump_details.append((jump_ea, final_target, chain.stage1_type))
            print(
                f"  Found {jump_match.group().hex()} @ 0x{jump_ea:X} targeting 0x{final_target:X}"
            )
        return self

    def sorted_targets(self):
        """
        Return a sorted list of (final_target, count) tuples.

        Sorting behavior depends on the stage1_type:
         - For STAGE1_MULTIPLE: sort by count descending, then by final_target descending.
         - For STAGE1_SINGLE: sort by count descending, then by the order in which the target was first seen.
           (That is, when counts are equal, the first inserted target wins.)
         - For other types, default to (count, final_target) descending.
        """
        results = []
        for target, count in self.jump_targets.items():
            stype = self.target_type.get(target)
            order = self.insertion_order.get(target, 0)
            if stype == SegmentType.STAGE1_SINGLE:
                key_tuple = (
                    count,
                    -order,
                )  # higher count, then lower insertion order (i.e. first seen)
            else:
                key_tuple = (count, target)  # higher count, then higher address
            results.append((target, key_tuple))
        results.sort(key=lambda x: x[1], reverse=True)
        # Return a list of (final_target, count) tuples.
        return [(target, self.jump_targets[target]) for target, _ in results]

    def __iter__(self):
        """
        Iterate over the most likely targets.
        For each candidate, if a jump exists whose starting address equals candidate + 1,
        yield its final target instead.
        """
        for candidate, count in self.sorted_targets():
            final_candidate = candidate
            for jump_ea, target, stype in self.jump_details:
                if jump_ea == candidate + 1:
                    final_candidate = target
                    break
            yield final_candidate


def find_stage1(mem, ea, end_ea):
    print("Searching for stage1 patterns from 0x{:X} to 0x{:X}".format(ea, end_ea))

    # Combine all patterns, keeping your original format
    patterns = [
        (
            MULTI_PART_PATTERNS,
            "Multi-Part Conditional Jumps",
            SegmentType.STAGE1_MULTIPLE,
        ),
        (
            SINGLE_PART_PATTERNS,
            "Single-Part Conditional Jumps",
            SegmentType.STAGE1_SINGLE,
        ),
    ]

    all_chains = MatchChains()
    for pattern_group, desc, segment_type in patterns:
        if not isinstance(pattern_group, list):
            pattern_group = [pattern_group]
        print(f"\nLooking for {desc} patterns:")
        for pattern in pattern_group:
            for m in pattern.compile().finditer(mem.mem_results):
                match_len = m.end() - m.start()
                matched_bytes = mem.mem_results[m.start() : m.end()]
                matched_groups = {
                    k: f"{v.hex()}" for k, v in m.groupdict().items() if k != "padding"
                }
                if "jump" in matched_groups:
                    offset = struct.unpack("<b", matched_bytes[-1:])[0]
                    target = ea + m.start() + match_len + offset
                    matched_groups["target"] = format_addr(target)
                elif "first_jump" in matched_groups:
                    offset = struct.unpack("<b", matched_bytes[1:2])[0]
                    matched_groups["first_target"] = format_addr(
                        ea + m.start() + 2 + offset
                    )
                    offset = struct.unpack("<b", matched_bytes[-1:])[0]
                    target = ea + m.start() + match_len + offset
                    matched_groups["second_target"] = format_addr(target)
                all_chains.add_chain(
                    MatchChain(
                        base_address=ea,
                        segments=[
                            MatchSegment(
                                start=m.start(),
                                length=match_len,
                                description=desc,
                                matched_bytes=matched_bytes,
                                segment_type=segment_type,
                                matched_groups=matched_groups,
                            )
                        ],
                    )
                )
    all_chains.sort()
    print(all_chains)
    return all_chains


# Function to find junk instructions after stage1 matches
def find_junk_instructions_after_stage1(mem, stage1_chains, start_ea, func_end):
    """
    - Register-based operations (0-57): ~58% chance.
    - RDTSC (58-60): ~3% chance.
    - PUSH imm32 (61-62): ~2% chance.
    - PUSH imm8 (63-65): ~3% chance.
    - Single-byte instructions (66-75): ~10% chance.
    - Conditional jumps with 8-bit offset (76-80): ~5% chance.
    - Conditional jumps with 32-bit offset (81-90): ~10% chance.
    - CALL instruction (91-99): ~9% chance.
    """
    print(
        f"\nPhase 2: Checking for junk instructions immediately following Stage1 matches"
    )

    for chain in stage1_chains:
        stage1_start = chain.overall_start()
        stage1_len = chain.overall_length()
        stage1_desc = chain.segments[0].description
        stage1_bytes = chain.overall_matched_bytes()

        # Calculate the position immediately after the Stage1 match in mem_results
        current_pos = stage1_start + stage1_len - start_ea
        if current_pos >= len(mem.mem_results):
            print(f"No room for junk after {stage1_desc} @ 0x{stage1_start:X}")
            continue

        # Extract the buffer after the Stage1 match
        post_stage1_buffer = mem.mem_results[current_pos:]
        total_junk_len = 0

        print(
            f"\nSearching for junk instruction sequence after {stage1_desc} at 0x{stage1_start:X} "
            f"(starting from 0x{stage1_start + stage1_len:X})"
        )

        # Iterate while there's enough space for another junk instruction (> 6 bytes)
        while len(post_stage1_buffer) > 6:
            junk_found = False
            for junk_pattern in JUNK_PATTERNS:
                match = junk_pattern.compile().match(post_stage1_buffer)
                if match:
                    junk_len = match.end() - match.start()
                    junk_bytes = post_stage1_buffer[:junk_len]
                    chain.append_junk(
                        junk_start=current_pos + total_junk_len,
                        junk_len=junk_len,
                        junk_desc=junk_pattern.description,
                        junk_bytes=junk_bytes,
                    )
                    total_junk_len += junk_len
                    post_stage1_buffer = post_stage1_buffer[junk_len:]
                    junk_found = True
                    print(
                        f"  Found {junk_pattern.description} @ 0x{stage1_start + stage1_len + total_junk_len - junk_len:X} "
                        f"({junk_len} bytes: {junk_bytes.hex()})"
                    )
                    break  # Move to the next portion of the buffer

            if not junk_found:
                print(
                    f"  No more junk instructions match with {len(post_stage1_buffer)} bytes remaining"
                )
                break  # Exit if no junk instruction matches
    stage1_chains.sort()
    print(stage1_chains)
    return stage1_chains


def find_big_instruction(buffer_bytes, is_x64=False):
    """
    Find the 'big instruction' in a 6-byte buffer, checking specific positions from the end.
    According to the constraints, the buffer will always be exactly 6 bytes.

    Args:
        buffer_bytes (bytes): The 6-byte buffer to analyze.
        is_x64 (bool): Whether to check for REX prefixes (x64 mode).

    Returns:
        dict: A dictionary containing information about the found instruction.
    """
    assert len(buffer_bytes) == 6, "Buffer must be exactly 6 bytes"

    # Function to check if a byte is a valid REX prefix (0x40-0x4F)
    def is_rex_prefix(byte):
        return 0x40 <= byte <= 0x4F

    # Function to check if a byte is a valid ModR/M byte (0x80-0xBF)
    def is_valid_modrm(byte):
        return 0x80 <= byte <= 0xBF

    # Ensure we have a 6-byte buffer
    if len(buffer_bytes) != 6:
        return {
            "type": None,
            "name": "Invalid buffer size",
            "instruction": [],
            "position": -1,
            "junk_before": buffer_bytes,
            "junk_after": [],
        }

    # 1. First check for 3-byte instructions in x64 mode (highest priority)
    if is_x64:
        # Check all possible positions for 3-byte instructions (REX + opcode + ModR/M)
        for pos in range(4):  # Start positions 0, 1, 2, 3
            if pos + 2 >= len(buffer_bytes):
                continue

            rex = buffer_bytes[pos]
            opcode = buffer_bytes[pos + 1]
            modrm = buffer_bytes[pos + 2]

            if is_rex_prefix(rex):
                # Check if it forms a valid 3-byte instruction
                if opcode in MED_OPCODE_SET and is_valid_modrm(modrm):
                    # Get junk bytes at the end (based on position)
                    junk_after = buffer_bytes[pos + 3 :]

                    # Verify junk bytes constraint for 3-byte instructions
                    expected_junk_bytes = max(0, 3 - pos)
                    if len(junk_after) == expected_junk_bytes:
                        return {
                            "type": "3-byte",
                            "name": "REX + Two-byte Med instruction",
                            "instruction": [rex, opcode, modrm],
                            "position": pos,
                            "junk_before": buffer_bytes[:pos],
                            "junk_after": junk_after,
                        }

                elif opcode in BIG_OPCODE_SET and is_valid_modrm(modrm):
                    # Get junk bytes at the end (based on position)
                    junk_after = buffer_bytes[pos + 3 :]

                    # Verify junk bytes constraint for 3-byte instructions
                    expected_junk_bytes = max(0, 3 - pos)
                    if len(junk_after) == expected_junk_bytes:
                        return {
                            "type": "3-byte",
                            "name": "REX + Two-byte Big instruction",
                            "instruction": [rex, opcode, modrm],
                            "position": pos,
                            "junk_before": buffer_bytes[:pos],
                            "junk_after": junk_after,
                        }

    # 2. Next check for 2-byte instructions
    for pos in range(5):  # Start positions 0, 1, 2, 3, 4
        if pos + 1 >= len(buffer_bytes):
            continue

        opcode = buffer_bytes[pos]
        modrm = buffer_bytes[pos + 1]

        # Check if it forms a valid 2-byte instruction
        if opcode in MED_OPCODE_SET and is_valid_modrm(modrm):
            # Get junk bytes at the end (based on position)
            junk_after = buffer_bytes[pos + 2 :]

            # Verify junk bytes constraint for 2-byte instructions
            expected_junk_bytes = max(0, 4 - pos)
            if len(junk_after) == expected_junk_bytes:
                return {
                    "type": "2-byte",
                    "name": "Two-byte Med instruction",
                    "instruction": [opcode, modrm],
                    "position": pos,
                    "junk_before": buffer_bytes[:pos],
                    "junk_after": junk_after,
                }

        elif opcode in BIG_OPCODE_SET and is_valid_modrm(modrm):
            # Get junk bytes at the end (based on position)
            junk_after = buffer_bytes[pos + 2 :]

            # Verify junk bytes constraint for 2-byte instructions
            expected_junk_bytes = max(0, 4 - pos)
            if len(junk_after) == expected_junk_bytes:
                return {
                    "type": "2-byte",
                    "name": "Two-byte Big instruction",
                    "instruction": [opcode, modrm],
                    "position": pos,
                    "junk_before": buffer_bytes[:pos],
                    "junk_after": junk_after,
                }

    # 3. Finally check for 1-byte instructions (lowest priority)
    pos = 5  # Only valid position for 1-byte instruction (last byte)
    if pos < len(buffer_bytes):
        byte = buffer_bytes[pos]
        if byte in SINGLE_BYTE_OPCODE_SET:
            return {
                "type": "1-byte",
                "name": "Single-byte big instruction",
                "instruction": [byte],
                "position": pos,
                "junk_before": buffer_bytes[:pos],
                "junk_after": [],  # No junk after 1-byte instruction at the end
            }

    # No valid instruction found
    return {
        "type": None,
        "name": "No match found",
        "instruction": [],
        "position": -1,
        "junk_before": buffer_bytes,
        "junk_after": [],
    }


def find_ending_big_instructions(mem, chains, start_ea, func_end):

    # Define big instruction patterns
    big_patterns = [
        (rb"[" + SINGLE_BYTE_OPCODES + rb"]", "Single-byte big instruction"),
        (rb"[" + MED_OPCODES + rb"][\x80-\xBF]", "Two-byte Med instruction"),
        (rb"[" + BIG_OPCODES + rb"][\x80-\xBF]", "Two-byte Big instruction"),
    ]
    if is_x64():
        big_patterns.append(
            (
                rb"[\x48-\x4F][" + MED_OPCODES + rb"][\x80-\xBF]",
                "REX + Two-byte Med instruction",
            )
        )
        big_patterns.append(
            (
                rb"[\x48-\x4F][" + BIG_OPCODES + rb"][\x80-\xBF]",
                "REX + Two-byte Big instruction",
            )
        )

    print(
        f"\nPhase 3: Checking for big instructions to find end of anti-disassembly block"
    )
    BUFFER_SIZE = 129  # Max size of anti-disassembly block

    for chain in chains:
        match_start = chain.overall_start()
        print(f"Analyzing match: {chain.description} @ 0x{match_start:X}")

        # Define the full anti-disassembly block
        block_end = match_start + BUFFER_SIZE

        # By the time this function, find_ending_big_instructions(), is called,
        # we've determined that the anti-disassembly stub is nearing its end, with
        # at most 6 bytes remaining before the transition to unobfuscated code.

        jump_targets = JumpTargetAnalyzer(
            chain.overall_matched_bytes(), match_start, block_end, start_ea
        ).process(mem=mem, chain=chain)
        for most_likely_target in jump_targets:
            # The most_likely_target represents the most likely jump target within the
            # stub—likely the point where execution exits to the unobfuscated code.
            # however, if we do not find a match, then we want to continue searching
            # previous targets and use those in decending order until we find a match
            print(
                f"most_likely_target: {most_likely_target:X}, block_end: {block_end:X}"
            )

            # Anti-disassembly stubs often use a "big instruction"
            # (e.g., one with a 32-bit operand, up to 6 bytes) just before the
            # final jump target to confuse disassemblers. Since most_likely_target
            # is the exit point, the big instruction must be located in the 6 bytes before it.
            search_start = most_likely_target - 6
            search_bytes = mem.mem_results[
                search_start - start_ea : most_likely_target - start_ea
            ]

            print(f"search_bytes: {search_bytes.hex()}")

            result = find_big_instruction(search_bytes, is_x64=is_x64())

            if not result["type"]:
                print("No valid instruction found.")
                # if we do not find a match, then we want to find the previous targets and use those
                # in decending order until we find a match
                continue

            junk_len = len(result["junk_after"]) if result["junk_after"] else 0
            if junk_len > 0:
                _m = f"    Junk bytes: {result['junk_after'].hex()} ({junk_len} bytes)"
                print(_m)
            instruction_bytes = bytes(result["instruction"])
            print(f"    Detected {result['name']}: {instruction_bytes.hex()} bytes")
            new_len = 6
            new_bytes = search_bytes
            # check for multiple anti-disassembly bytes after search_start + 6
            # if found, then we want to add them to the new_bytes
            for i in itertools.count():
                b = mem.mem_results[search_start - start_ea + 6 + i]
                if b != ANTI_DISASM_EXTRA_BYTE:
                    if i != 0:
                        print(
                            f"    Found {i} extra anti-disassembly bytes @ 0x{search_start + 6:X}"
                        )
                    break
                new_bytes = bytes(b)
                new_len += 1

            chain.add_segment(
                MatchSegment(
                    start=search_start - start_ea,
                    length=new_len,
                    description=result["name"],
                    matched_bytes=new_bytes,
                    segment_type=SegmentType.BIG_INSTRUCTION,
                )
            )
            break
        else:
            print("No big instruction found...hmm, unlikely!")
    chains.sort()
    return chains


def filter_match_chains(match_chains):
    """
    Filters out match chains that are false positives based on two criteria:
      - The total length of the anti-disassembly routine must be between 12 and 129 bytes.
      - The junk length must be nonzero.
    """
    valid_chains = []
    for chain in match_chains:
        total_length = chain.overall_length()
        junk_length = (
            chain.junk_length
        )  # assumes this property returns the total length of junk instructions
        if junk_length == 0:
            # Likely a false positive since no junk instructions were found.
            continue
        if total_length < 12 or total_length > 129:
            # Stub does not meet size constraints.
            continue
        valid_chains.append(chain)
    return valid_chains


def filter_antidisasm_patterns(mem, chains, start_ea, min_size=12, max_size=129):
    """
    Filter out false positive anti-disassembly patterns and handle overlaps.
    Integrates with existing big instruction detection code.

    Args:
        chains: List of MatchChain objects
        mem: Memory object containing binary data
        start_ea: Starting effective address
        min_size: Minimum valid size for an anti-disassembly routine (default: 12)
        max_size: Maximum valid size for an anti-disassembly routine (default: 129)

    Returns:
        List of validated MatchChain objects
    """
    print(f"\nFiltering {len(chains)} potential anti-disassembly patterns...")

    # Stage 1: Basic filtering based on size and junk presence
    print("Stage 1: Basic validation")
    filtered_chains = []

    for chain in chains:

        # Apply basic filters
        length = chain.overall_length()
        if length < min_size or length > max_size:
            print(
                f"  Rejected: {chain.description} @ 0x{chain.overall_start():X} - length {length} outside valid range {min_size}-{max_size}"
            )
            continue

        if not chain.junk_segments or chain.junk_length == 0:
            print(
                f"  Rejected: {chain.description} @ 0x{chain.overall_start():X} - no junk instructions"
            )
            continue

        # If big instruction hasn't been detected yet, we'll validate it in Stage 2
        filtered_chains.append(chain)

    print(f"  After basic filtering: {len(filtered_chains)} chains remain")

    # Stage 2: Validate big instructions if not already done
    print("Stage 2: Big instruction validation")
    validated_with_big_instr = []

    for chain in filtered_chains:
        # Check if we already have a big instruction segment
        if any(
            seg.segment_type == SegmentType.BIG_INSTRUCTION for seg in chain.segments
        ):
            validated_with_big_instr.append(chain)
            continue

        # Find the big instruction
        match_start = chain.overall_start()
        chain_end = match_start + max_size

        print(f"Analyzing match: {chain.description} @ 0x{match_start:X}")

        # Determine possible jump targets - using your existing code
        jump_targets = JumpTargetAnalyzer(
            chain.overall_matched_bytes(), match_start, chain_end, start_ea
        ).process(mem=mem, chain=chain)

        big_instr_found = False

        for target in jump_targets:
            # The most_likely_target represents the most likely jump target within the
            # stub—likely the point where execution exits to the unobfuscated code.
            # however, if we do not find a match, then we want to continue searching
            # previous targets and use those in decending order until we find a match
            print(f"most_likely_target: 0x{target:X}, block_end: {chain_end:X}")
            # Check for big instruction in the 6 bytes before target
            # a big instruction (e.g., one with a 32-bit operand, up to 6 bytes)
            # just before the final jump target to confuse disassemblers.
            search_start = target - 6
            if search_start < start_ea:
                continue

            # Extract the 6-byte buffer
            buffer_offset = search_start - start_ea
            target_offset = target - start_ea

            if buffer_offset < 0 or target_offset > len(mem.mem_results):
                continue

            search_bytes = mem.mem_results[buffer_offset:target_offset]
            print(f"search_bytes: {search_bytes.hex()}")
            if len(search_bytes) != 6:
                continue  # Skip if we can't get exactly 6 bytes

            # Use your existing function to find big instruction
            result = find_big_instruction(search_bytes, is_x64=is_x64())
            if not result["type"]:
                print("No valid instruction found.")
                # if we do not find a match, then we want to find the previous targets and use those
                # in decending order until we find a match
                continue

            # Found a valid big instruction
            big_instr_found = True

            junk_len = len(result["junk_after"]) if result["junk_after"] else 0
            if junk_len > 0:
                _m = f"    Junk bytes: {result['junk_after'].hex()} ({junk_len} bytes)"
                print(_m)
            instruction_bytes = bytes(result["instruction"])
            print(f"    Detected {result['name']}: {instruction_bytes.hex()} bytes")

            # check for multiple anti-disassembly bytes after search_start + 6
            # if found, then we want to add them to the new_bytes
            new_len = 6
            new_bytes = search_bytes

            # Check for additional anti-disassembly bytes
            for i in itertools.count():
                extra_offset = buffer_offset + 6 + i

                b = mem.mem_results[extra_offset]
                if b != ANTI_DISASM_EXTRA_BYTE:
                    if i != 0:
                        print(
                            f"    Found {i} extra anti-disassembly bytes @ 0x{search_start + 6:X}"
                        )
                    break

                new_bytes += bytes([b])
                new_len += 1

            chain.add_segment(
                MatchSegment(
                    start=buffer_offset,
                    length=new_len,
                    description=result["name"],
                    matched_bytes=new_bytes,
                    segment_type=SegmentType.BIG_INSTRUCTION,
                )
            )
            break

        if big_instr_found:
            validated_with_big_instr.append(chain)
        else:
            print(
                f"  Rejected: {chain.description} @ 0x{chain.overall_start():X} - no valid big instruction"
            )

    print(
        f"  After big instruction validation: {len(validated_with_big_instr)} chains remain"
    )

    # Stage 3: Handle overlapping patterns
    print("Stage 3: Resolving overlaps")

    # Sort chains by start address
    sorted_chains = sorted(validated_with_big_instr, key=lambda c: c.overall_start())
    final_chains = []
    covered_ranges = []

    for chain in sorted_chains:
        chain_start = chain.overall_start()

        # Calculate chain end including the big instruction
        big_instr_segments = [
            seg
            for seg in chain.segments
            if seg.segment_type == SegmentType.BIG_INSTRUCTION
        ]
        if big_instr_segments:
            # Use the end of the big instruction as the chain end
            big_instr = big_instr_segments[-1]
            offset_in_mem = big_instr.start
            chain_end = start_ea + offset_in_mem + big_instr.length
        else:
            # Fallback to overall length if no big instruction (shouldn't happen at this point)
            chain_end = chain_start + chain.overall_length()

        # Check if this chain overlaps with an already accepted chain
        is_covered = False
        for start, end in covered_ranges:
            # Check if this chain starts within a covered range
            if chain_start >= start and chain_start < end:
                print(
                    f"  Rejected overlap: {chain.description} @ 0x{chain_start:X} - starts within existing pattern ({start:X} to {end:X})"
                )
                is_covered = True
                break

        if not is_covered:
            final_chains.append(chain)
            covered_ranges.append((chain_start, chain_end))
            print(
                f"  Accepted: {chain.description} @ 0x{chain_start:X} - valid pattern to 0x{chain_end:X}"
            )

    print(f"Filtering complete: {len(final_chains)} of {len(chains)} chains accepted")
    return final_chains


def process(start_ea, end_ea, patch_operations):
    mem = MemHelper(start_ea, end_ea)
    chains = find_stage1(mem, start_ea, end_ea)
    if not chains:
        print("No stage1 matches found!")
        return

    chains = find_junk_instructions_after_stage1(mem, chains, start_ea, end_ea)
    chains = filter_match_chains(chains)
    # chains = find_ending_big_instructions(mem, chains, start_ea, end_ea)
    chains = filter_antidisasm_patterns(mem, chains, start_ea)
    print("=== Updated matches ===")
    chains.sort()
    for chain in chains:
        print(chain)
        patch_operations.append(
            PatchOperation(chain.overall_start(), b"\x90" * chain.overall_length())
        )
    return patch_operations


def execute_action(start_ea: int, end_ea: int, patch=False):
    """
    Main entry point for script.

    Args:
        patch: Whether to apply patches immediately
        using_combined_approach: Whether to use the combined stage1/deflow approach
    """
    print("Starting search...")
    patch_operations = []
    process(start_ea, end_ea, patch_operations)
    print("\nSearch completed.")
    if patch:
        print("Applying patches...")
        for patch in patch_operations:
            patch.apply()
        print("Patches applied.")


@dataclasses.dataclass
class RemoveantidisassemblyActionHandler(ida_helpers.BaseActionHandler):
    """Remove Anti Disassembly"""

    action_name: str = "mutilz:remove_anti_disassembly"
    action_label: str = "Remove Anti Disassembly"
    icon: int = 19

    def get_selected_addresses(self):
        is_selected, start_ea, end_ea = idaapi.read_range_selection(
            idaapi.get_current_viewer()
        )
        if is_selected and start_ea != idaapi.BADADDR and end_ea != idaapi.BADADDR:
            # reset ea to start_ea since we selected a range specifically to the
            # start and end of the range
            return start_ea, end_ea

        print("No range selected!")
        if not start_ea:
            start_ea = idaapi.get_screen_ea()
            print(
                f"Cannot determine start address, using current address: 0x{start_ea:X}"
            )
        end_ea = ida_kernwin.ask_addr(start_ea, "Enter end address for selection:")
        if end_ea is None:
            print("Selection canceled. Returning start address.")
            return start_ea, None
        if end_ea <= start_ea:
            print("Error: End address must be greater than start address.")
            return start_ea, None
        return start_ea, end_ea

    def activate(self, ctx):
        ea = idaapi.get_screen_ea()
        func = ida_funcs.get_func(ea)
        if func:
            start_ea = func.start_ea
            end_ea = func.end_ea
        else:
            start_ea, end_ea = self.get_selected_addresses()
        try:
            clear_output()
            execute_action(start_ea, end_ea, patch=True)
        finally:
            idc.jumpto(start_ea)

    def update(self, ctx):
        match ctx.widget_type:
            case idaapi.BWN_DISASM:
                return idaapi.AST_ENABLE_FOR_WIDGET
            case _:
                return idaapi.AST_DISABLE_FOR_WIDGET


class RemoveantidisassemblyAction(
    actions.action_t, metaclass=ida_helpers.HookedActionMeta
):
    uihook_class = functools.partial(
        ida_helpers.PopUpHook,
        RemoveantidisassemblyActionHandler,
        ida_helpers.is_disassembly_widget,
    )


# retrieve the action
def get_action() -> actions.action_t:
    return RemoveantidisassemblyAction()


# Failing test case:

"""
.text:000000014000CB71 188 A9 32 A0 32 7C                                      test    eax, 7C32A032h
.text:000000014000CB76 188 73 2D                                               jnb     short near ptr loc_14000CBA2+3
.text:000000014000CB78 188 81 C1 E5 46 50 B3                                   add     ecx, 0B35046E5h
.text:000000014000CB7E 188 80 C1 61                                            add     cl, 61h ; 'a'
.text:000000014000CB81 188 0F 80 4B 20 01 00                                   jo      near ptr loc_14001EBCD+5
.text:000000014000CB87 188 0F 31                                               rdtsc
.text:000000014000CB89 188 81 E9 C5 1C 77 72                                   sub     ecx, 72771CC5h
.text:000000014000CB8F 188 0F 31                                               rdtsc
.text:000000014000CB91 188 6A BE                                               push    0FFFFFFFFFFFFFFBEh
.text:000000014000CB93 190 83 C6 85                                            add     esi, 0FFFFFF85h
.text:000000014000CB96 190 81 C3 0C 69 C0 43                                   add     ebx, 43C0690Ch
.text:000000014000CB9C 190 81 E8 22 13 CE 92                                   sub     eax, 92CE1322h
.text:000000014000CBA2
.text:000000014000CBA2                                         loc_14000CBA2:                          ; CODE XREF: InitAegisContext(_ANTIDEBUG_CONTEXT *)+21D6↑j
.text:000000014000CBA2 190 88 82 A0 48 8B 44                                   mov     [rdx+448B48A0h], al
.text:000000014000CBA8 190 24 58                                               and     al, 58h
.text:000000014000CBAA 190 48 C1 E8 34                                         shr     rax, 34h
.text:000000014000CBAE 190 41 8B D0                                            mov     edx, r8d
.text:000000014000CBB1 190 4A 8B 8C 20 80 28 B7 02                             mov     rcx, [rax+r12+2B72880h]
.text:000000014000CBB9 190 41 8B C0                                            mov     eax, r8d
.text:000000014000CBBC 190 C1 C9 0B                                            ror     ecx, 0Bh
.text:000000014000CBBF 190 4D 23 C5                                            and     r8, r13
.text:000000014000CBC2 190 F7 D0                                               not     eax
.text:000000014000CBC4 190 33 C8                                               xor     ecx, eax
.text:000000014000CBC6 190 48 C1 E1 20                                         shl     rcx, 20h
.text:000000014000CBCA 190 49 33 C8                                            xor     rcx, r8
.text:000000014000CBCD 190 48 0B CA                                            or      rcx, rdx
.text:000000014000CBD0 190 4A 89 8C 23 A8 38 B7 02                             mov     [rbx+r12+2B738A8h], rcx
.text:000000014000CBD8 190 0F 1F 84 00 00 00 00 00                             nop     dword ptr [rax+rax+00000000h]
"""

# debug output:

"""
Starting search...
Searching for stage1 patterns from 0x14000A9A0 to 0x14000CD62

Looking for Multi-Part Conditional Jumps patterns:

Looking for Single-Part Conditional Jumps patterns:
   Single-Part Conditional Jumps @ 0x14000B121 - f6c376732f
   Single-Part Conditional Jumps @ 0x14000CB71 - a932a0327c732d

Phase 2: Checking for junk instructions immediately following Stage1 matches

Searching for junk instruction sequence after Single-Part Conditional Jumps at 0x14000B121 (starting from 0x14000B126)
  Found Random 112-127 @ 0x14000B126 (2 bytes: 7a99)
  No more junk instructions match with 7226 bytes remaining

Searching for junk instruction sequence after Single-Part Conditional Jumps at 0x14000CB71 (starting from 0x14000CB78)
  Found ADD reg32, imm32 @ 0x14000CB78 (6 bytes: 81c1e54650b3)
  Found ADD reg8, imm8 @ 0x14000CB7E (3 bytes: 80c161)
  Found TwoByte Conditional Jump @ 0x14000CB81 (6 bytes: 0f804b200100)
  Found RDTSC @ 0x14000CB87 (2 bytes: 0f31)
  Found AND reg32, imm32 @ 0x14000CB89 (6 bytes: 81e9c51c7772)
  Found RDTSC @ 0x14000CB8F (2 bytes: 0f31)
  Found PUSH imm8 @ 0x14000CB91 (2 bytes: 6abe)
  Found ADD reg32, imm8 @ 0x14000CB93 (3 bytes: 83c685)
  Found ADD reg32, imm32 @ 0x14000CB96 (6 bytes: 81c30c69c043)
  Found AND reg32, imm32 @ 0x14000CB9C (6 bytes: 81e82213ce92)
  No more junk instructions match with 448 bytes remaining
Single-Part Conditional Jumps -> Random 112-127 @ 0x14000B121 - f6c376732f7a99
Single-Part Conditional Jumps -> ADD reg32, imm32 -> ADD reg8, imm8 -> TwoByte Conditional Jump -> RDTSC -> AND reg32, imm32 -> RDTSC -> PUSH imm8 -> ADD reg32, imm8 -> ADD reg32, imm32 -> AND reg32, imm32 @ 0x14000CB71 - a932a0327c732d81...

Filtering 1 potential anti-disassembly patterns...
Stage 1: Basic validation
  After basic filtering: 1 chains remain
Stage 2: Big instruction validation
Analyzing match: Single-Part Conditional Jumps -> ADD reg32, imm32 -> ADD reg8, imm8 -> TwoByte Conditional Jump -> RDTSC -> AND reg32, imm32 -> RDTSC -> PUSH imm8 -> ADD reg32, imm8 -> ADD reg32, imm32 -> AND reg32, imm32 @ 0x14000CB71
  -> Found jl      short loc_14000CBEA @ 0x14000CB75 targeting 0x14000CBEA
  7c73 @ 0x14000CB75 targeting 0x14000CB75 is NOT within 6 bytes of match end 14000CBA2
  -> Found ja      short loc_14000CC01 @ 0x14000CB8D targeting 0x14000CC01
  7772 @ 0x14000CB8D targeting 0x14000CB8D is NOT within 6 bytes of match end 14000CBA2
  Rejected: Single-Part Conditional Jumps -> ADD reg32, imm32 -> ADD reg8, imm8 -> TwoByte Conditional Jump -> RDTSC -> AND reg32, imm32 -> RDTSC -> PUSH imm8 -> ADD reg32, imm8 -> ADD reg32, imm32 -> AND reg32, imm32 @ 0x14000CB71 - no valid big instruction
  After big instruction validation: 0 chains remain
Stage 3: Resolving overlaps
Filtering complete: 0 of 1 chains accepted
"""
